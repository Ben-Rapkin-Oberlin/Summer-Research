{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-05-30T19:55:48.606664Z",
          "iopub.status.busy": "2023-05-30T19:55:48.606219Z",
          "iopub.status.idle": "2023-05-30T19:55:48.613668Z",
          "shell.execute_reply": "2023-05-30T19:55:48.612505Z",
          "shell.execute_reply.started": "2023-05-30T19:55:48.606628Z"
        },
        "id": "DKhGjRvvO8ek",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "# data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-05-30T19:55:48.626413Z",
          "iopub.status.busy": "2023-05-30T19:55:48.625629Z",
          "iopub.status.idle": "2023-05-30T19:55:48.637788Z",
          "shell.execute_reply": "2023-05-30T19:55:48.636462Z",
          "shell.execute_reply.started": "2023-05-30T19:55:48.626376Z"
        },
        "id": "hYBzEiWMO8em",
        "outputId": "e943edeb-12df-4b7f-e69b-4360e5cfe1ec",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ray in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from ray) (23.1.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.12.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.5)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (6.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.27.1)\n",
            "Requirement already satisfied: virtualenv<20.21.1,>=20.0.24 in /usr/local/lib/python3.10/dist-packages (from ray) (20.21.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray) (23.1)\n",
            "Requirement already satisfied: grpcio<=1.51.3,>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.51.3)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from ray) (1.22.4)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv<20.21.1,>=20.0.24->ray) (0.3.6)\n",
            "Requirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.10/dist-packages (from virtualenv<20.21.1,>=20.0.24->ray) (3.3.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.19.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.4.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.11.4)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.27.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.10/dist-packages (2.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (23.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#!pip install ray\n",
        "#!pip install -U tensorboardx\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from functools import partial\n",
        "import os\n",
        "from filelock import FileLock\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "from ray import air, tune\n",
        "from ray.air import Checkpoint, session\n",
        "from ray.air.config import RunConfig, ScalingConfig, CheckpointConfig\n",
        "from ray.tune.schedulers import ASHAScheduler, PopulationBasedTraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2023-05-30T19:55:48.663792Z",
          "iopub.status.busy": "2023-05-30T19:55:48.662917Z",
          "iopub.status.idle": "2023-05-30T19:55:48.681769Z",
          "shell.execute_reply": "2023-05-30T19:55:48.680649Z",
          "shell.execute_reply.started": "2023-05-30T19:55:48.663729Z"
        },
        "id": "owQqUbwSO8eo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#@title old net\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, l1=12, l2=10,p=0.2):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1=nn.Linear(784, l1) # 16 input features, 12 output features also called neurons\n",
        "        self.fc2=nn.Linear(l1, l2)\n",
        "        self.out=nn.Linear(l2, 10)\n",
        "        self.m = nn.LogSoftmax(dim=0)\n",
        "        self.drop = nn.Dropout(p)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x=x.squeeze()\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.drop(x)\n",
        "       \n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.drop(x)\n",
        "       \n",
        "        x=self.out(x)\n",
        "        x = F.relu(x)\n",
        "        #x = self.drop(x)\n",
        "        output = self.m(x)\n",
        "        \n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-05-30T19:55:48.718889Z",
          "iopub.status.busy": "2023-05-30T19:55:48.718200Z",
          "iopub.status.idle": "2023-05-30T19:55:48.825600Z",
          "shell.execute_reply": "2023-05-30T19:55:48.824157Z",
          "shell.execute_reply.started": "2023-05-30T19:55:48.718834Z"
        },
        "id": "OlsNDlqWO8eq",
        "outputId": "cf24278e-69e8-45a8-9831-f81603988306",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 784])\n",
            "torch.Size([10000, 784])\n"
          ]
        }
      ],
      "source": [
        "#@title og load data\n",
        "def load_data(data_dir=\"/kaggle/working/\"):\n",
        "    training_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"data_dir\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        "    )\n",
        "\n",
        "    test_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"data_dir\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        "    )\n",
        "    training_data.data=torch.flatten(training_data.data, start_dim=1)\n",
        "    test_data.data=torch.flatten(test_data.data, start_dim=1)\n",
        "    #print(training_data.data.shape)\n",
        "    return training_data, test_data\n",
        "#t,te=load_data()\n",
        "#print(t.data.shape)\n",
        "#print(te.data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T19:55:48.828000Z",
          "iopub.status.busy": "2023-05-30T19:55:48.827217Z",
          "iopub.status.idle": "2023-05-30T19:55:55.723377Z",
          "shell.execute_reply": "2023-05-30T19:55:55.722379Z",
          "shell.execute_reply.started": "2023-05-30T19:55:48.827955Z"
        },
        "id": "1WTMJ6B1O8er",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#@title accuracy\n",
        "def test_accuracy(net, device=\"cpu\"):\n",
        "    _, testset = load_data()\n",
        "\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset, batch_size=4, shuffle=False, num_workers=2\n",
        "    )\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        c=0\n",
        "        for data in testloader:\n",
        "                  #  c+=1\n",
        "                    #if (c==2500):\n",
        "                       # print('g',c)\n",
        "                    #    break\n",
        "                    images, labels = data\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    #print(images.shape)\n",
        "                    outputs = net(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "    return correct / total\n",
        "#print(test_accuracy(Net(16,8)))\n",
        "#print(test_accuracy(Net(16,8)))\n",
        "#print(test_accuracy(Net(16,8)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T19:55:55.726820Z",
          "iopub.status.busy": "2023-05-30T19:55:55.726136Z",
          "iopub.status.idle": "2023-05-30T19:55:55.749544Z",
          "shell.execute_reply": "2023-05-30T19:55:55.748574Z",
          "shell.execute_reply.started": "2023-05-30T19:55:55.726781Z"
        },
        "id": "9judIZFoO8es",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_cifar(config,epochs=10,data_dir=None,trainset=None,testset=None,tune=False):\n",
        "    net = Net(l1=config[\"l1\"],l2=config[\"l2\"],p=config[\"dropout\"])\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            net = nn.DataParallel(net)\n",
        "            \n",
        "    net.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    if config[\"opt\"]==\"SGD\":\n",
        "        #if tune:\n",
        "           # config[\"p\"]=np.random.uniform(low=.85, high=.95)\n",
        "        optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=.9)\n",
        "        \n",
        "    elif config[\"opt\"]==\"Adam\":\n",
        "        optimizer = optim.Adam(net.parameters(),lr=0)# lr=config[\"lr\"])\n",
        "        \n",
        "    start_epoch = 0\n",
        "    if tune:\n",
        "        checkpoint = session.get_checkpoint()\n",
        "\n",
        "        if checkpoint:\n",
        "            checkpoint_state = checkpoint.to_dict()\n",
        "            start_epoch = checkpoint_state[\"epoch\"]\n",
        "            net.load_state_dict(checkpoint_state[\"net_state_dict\"])\n",
        "            optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\n",
        "\n",
        "    \n",
        "    test_abs = int(len(trainset) * 0.8)\n",
        "    train_subset, val_subset = random_split(\n",
        "        trainset, [test_abs, len(trainset) - test_abs]\n",
        "    )\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        train_subset, batch_size=int(config[\"batch_size\"]), shuffle=True, num_workers=2\n",
        "    )\n",
        "    valloader = torch.utils.data.DataLoader(\n",
        "        val_subset, batch_size=int(config[\"batch_size\"]), shuffle=True, num_workers=2\n",
        "    )\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        epoch_steps = 0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            \n",
        "            #print(labels)\n",
        "            \n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            epoch_steps += 1\n",
        "           \n",
        "\n",
        "        # Validation loss\n",
        "        val_loss = 0.0\n",
        "        val_steps = 0\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for i, data in enumerate(valloader, 0):\n",
        "            with torch.no_grad():\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = net(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.cpu().numpy()\n",
        "                val_steps += 1\n",
        "\n",
        "        if tune:\n",
        "            checkpoint_data = {\n",
        "                       \"epoch\": epoch,\n",
        "                        \"net_state_dict\": net.state_dict(),\n",
        "                        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            }\n",
        "            checkpoint = Checkpoint.from_dict(checkpoint_data)\n",
        "            session.report(\n",
        "                        {\"loss\": val_loss / val_steps, \"accuracy\": correct / total},\n",
        "                        checkpoint=checkpoint,\n",
        "                )\n",
        "            \"\"\"\n",
        "            if config[\"opt\"]==\"SGD\":\n",
        "                session.report(\n",
        "                        {\"loss\": val_loss / val_steps, \"accuracy\": correct / total},\n",
        "                        checkpoint=checkpoint,\n",
        "                )\n",
        "            elif config[\"opt\"]==\"Adam\":\n",
        "                session.report(\n",
        "                        {\"loss\": 50, \"accuracy\": correct / total},\n",
        "                        checkpoint=checkpoint,\n",
        "                )\n",
        "              \"\"\"\n",
        "        else:\n",
        "            if epoch%5==0:\n",
        "                print(\"epoch,val loss,%correct\",epoch,val_loss,correct/total)\n",
        "    print(\"Finished Training\")\n",
        "    \n",
        "    return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBUie-Du_Rpq"
      },
      "outputs": [],
      "source": [
        "#@title hp3\n",
        "def hyperparam_search2(config,scheduler=\"ASHA\",cpu=4,gpu=0,max_num_epochs=10,concurrent=1):\n",
        "   #determins how the searching works\n",
        "    if scheduler==\"ASHA\":\n",
        "        #tries various permutations of parameters\n",
        "        sched = ASHAScheduler(\n",
        "            #metric=\"loss\",\n",
        "            #mode=\"min\",\n",
        "            #mode=\"max\",\n",
        "            max_t=max_num_epochs,\n",
        "            grace_period=1,\n",
        "            reduction_factor=2,\n",
        "        )\n",
        "    \n",
        "    if scheduler==\"PB2\":\n",
        "        pass\n",
        "    \n",
        "    trainset, testset = load_data()  \n",
        "\n",
        "    tuner = tune.Tuner(\n",
        "        tune.with_parameters(train_cifar,trainset=trainset,testset=testset,tune=True),\n",
        "        param_space=config,\n",
        "        tune_config=tune.TuneConfig(\n",
        "           # num_samples=num_samples, different when using grid search\n",
        "            metric=\"loss\",\n",
        "            mode=\"min\",\n",
        "            scheduler=sched,\n",
        "            max_concurrent_trials=concurrent\n",
        "            )\n",
        "    )\n",
        "       \n",
        "    results = tuner.fit()\n",
        "\n",
        "    \n",
        "    best_trial = results.get_best_result(metric=\"loss\", mode=\"min\")\n",
        "    print(f\"Best trial config: {best_trial.config}\")\n",
        "    print(f\"Best trial final validation loss: {best_trial.metrics['loss']}\")\n",
        "    print(f\"Best trial final validation accuracy: {best_trial.metrics['accuracy']}\")\n",
        "    \n",
        "    return best_trial.config\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2023-05-30T19:55:55.776597Z",
          "iopub.status.busy": "2023-05-30T19:55:55.776197Z",
          "iopub.status.idle": "2023-05-30T19:55:55.790659Z",
          "shell.execute_reply": "2023-05-30T19:55:55.789297Z",
          "shell.execute_reply.started": "2023-05-30T19:55:55.776565Z"
        },
        "id": "KMMaWRxzO8ev",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#@title og hps\n",
        "def hyperparam_search(config,scheduler=\"ASHA\",cpu=4,gpu=0,num_samples=20,max_num_epochs=10):\n",
        "    \n",
        "    #determins how the searching works\n",
        "    if scheduler==\"ASHA\":\n",
        "        #tries various permutations of parameters\n",
        "        scheduler = ASHAScheduler(\n",
        "            metric=\"loss\",\n",
        "            #mode=\"min\",\n",
        "            mode=\"max\",\n",
        "            max_t=max_num_epochs,\n",
        "            grace_period=1,\n",
        "            reduction_factor=2,\n",
        "        )\n",
        "    \n",
        "    if scheduler==\"PB2\":\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    trainset, testset = load_data()\n",
        "    \n",
        "    \n",
        "    result = tune.run(\n",
        "        partial(train_cifar,trainset=trainset,testset=testset,tune=True),\n",
        "        resources_per_trial={\"cpu\": cpu, \"gpu\": gpu},\n",
        "        config=config,\n",
        "        #num_samples=num_samples,\n",
        "        scheduler=scheduler,\n",
        "        verbose=1\n",
        "        \n",
        "    )\n",
        "    return    \n",
        "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
        "    \n",
        "    print(f\"Best trial config: {best_trial.config}\")\n",
        "    print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
        "    print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")\n",
        "    \n",
        "\n",
        "    best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if gpus_per_trial > 1:\n",
        "            best_trained_model = nn.DataParallel(best_trained_model)\n",
        "    best_trained_model.to(device)\n",
        "\n",
        "    best_checkpoint = best_trial.checkpoint.to_air_checkpoint()\n",
        "    best_checkpoint_data = best_checkpoint.to_dict()\n",
        "    best_trained_model.load_state_dict(best_checkpoint_data[\"net_state_dict\"])\n",
        "    test_acc = test_accuracy(best_trained_model, device)\n",
        "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
        "    return best_trial.config\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T19:55:55.792658Z",
          "iopub.status.busy": "2023-05-30T19:55:55.792144Z",
          "iopub.status.idle": "2023-05-30T19:55:55.807636Z",
          "shell.execute_reply": "2023-05-30T19:55:55.806549Z",
          "shell.execute_reply.started": "2023-05-30T19:55:55.792623Z"
        },
        "id": "vACehOR2O8ew",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "\n",
        "    search_space = {\n",
        "        #\"opt\": tune.grid_search([\"Adam\",\"SGD\"]),\n",
        "        \"opt\": \"SGD\",\n",
        "        \"l1\": tune.grid_search([2**i for i in range(4,6)]),\n",
        "        #\"l2\": tune.grid_search([2**i for i in range(4,7)]),\n",
        "        \"l2\":16,\n",
        "        #\"lr\": loguniform.rvs(1e-4, 1e-1, size=1)[0],#tune.loguniform(1e-4, 1e-1),\n",
        "        \"lr\": 0.01,\n",
        "        #\"batch_size\": tune.grid_search([32,64]),\n",
        "        \"batch_size\": 32,\n",
        "        #\"dropout\": np.random.uniform(low=.1, high=.3),\n",
        "        \"dropout\": 0.2, \n",
        "    }\n",
        "    \n",
        "\n",
        "    best_config=hyperparam_search2(search_space,scheduler=\"ASHA\",cpu=2,gpu=0,max_num_epochs=1,concurrent=0)\n",
        "\n",
        "\n",
        "    print(\"--------training model--------\")\n",
        "    trainset, testset = load_data()\n",
        "    net=train_cifar(best_config,epochs=200,trainset=trainset,testset=testset)\n",
        "    test_acc = test_accuracy(net)\n",
        "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
        "    torch.save(net,'/working')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "execution": {
          "iopub.execute_input": "2023-05-30T19:55:55.809654Z",
          "iopub.status.busy": "2023-05-30T19:55:55.809263Z",
          "iopub.status.idle": "2023-05-30T19:56:16.137109Z",
          "shell.execute_reply": "2023-05-30T19:56:16.135339Z",
          "shell.execute_reply.started": "2023-05-30T19:55:55.809623Z"
        },
        "id": "w4hKqCTEO8ew",
        "outputId": "4a247ea5-d8e9-428d-edaa-0a5115e24388",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div class=\"tuneStatus\">\n",
              "  <div style=\"display: flex;flex-direction: row\">\n",
              "    <div style=\"display: flex;flex-direction: column;\">\n",
              "      <h3>Tune Status</h3>\n",
              "      <table>\n",
              "<tbody>\n",
              "<tr><td>Current time:</td><td>2023-06-01 01:05:20</td></tr>\n",
              "<tr><td>Running for: </td><td>00:00:53.06        </td></tr>\n",
              "<tr><td>Memory:      </td><td>4.0/12.7 GiB       </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "    </div>\n",
              "    <div class=\"vDivider\"></div>\n",
              "    <div class=\"systemInfo\">\n",
              "      <h3>System Info</h3>\n",
              "      Using AsyncHyperBand: num_stopped=2<br>Bracket: Iter 1.000: -1.103267204761505<br>Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
              "    </div>\n",
              "    \n",
              "  </div>\n",
              "  <div class=\"hDivider\"></div>\n",
              "  <div class=\"trialStatus\">\n",
              "    <h3>Trial Status</h3>\n",
              "    <table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">  l1</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_cifar_41489_00000</td><td>TERMINATED</td><td>172.28.0.12:47538</td><td style=\"text-align: right;\">  16</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         39.3584</td><td style=\"text-align: right;\">1.10826</td><td style=\"text-align: right;\">  0.628667</td></tr>\n",
              "<tr><td>train_cifar_41489_00001</td><td>TERMINATED</td><td>172.28.0.12:47595</td><td style=\"text-align: right;\">  32</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         34.1798</td><td style=\"text-align: right;\">1.09828</td><td style=\"text-align: right;\">  0.655083</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "  </div>\n",
              "</div>\n",
              "<style>\n",
              ".tuneStatus {\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".tuneStatus .systemInfo {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              ".tuneStatus .trialStatus {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tuneStatus .hDivider {\n",
              "  border-bottom-width: var(--jp-border-width);\n",
              "  border-bottom-color: var(--jp-border-color0);\n",
              "  border-bottom-style: solid;\n",
              "}\n",
              ".tuneStatus .vDivider {\n",
              "  border-left-width: var(--jp-border-width);\n",
              "  border-left-color: var(--jp-border-color0);\n",
              "  border-left-style: solid;\n",
              "  margin: 0.5em 1em 0.5em 1em;\n",
              "}\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div class=\"trialProgress\">\n",
              "  <h3>Trial Progress</h3>\n",
              "  <table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th style=\"text-align: right;\">  accuracy</th><th>date               </th><th>done  </th><th>hostname    </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">   loss</th><th>node_ip    </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  training_iteration</th><th style=\"text-align: right;\">   trial_id</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_cifar_41489_00000</td><td style=\"text-align: right;\">  0.628667</td><td>2023-06-01_01-05-13</td><td>True  </td><td>11b6545873f0</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">1.10826</td><td>172.28.0.12</td><td style=\"text-align: right;\">47538</td><td>True               </td><td style=\"text-align: right;\">             39.3584</td><td style=\"text-align: right;\">           39.3584</td><td style=\"text-align: right;\">       39.3584</td><td style=\"text-align: right;\"> 1685581513</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">41489_00000</td></tr>\n",
              "<tr><td>train_cifar_41489_00001</td><td style=\"text-align: right;\">  0.655083</td><td>2023-06-01_01-05-19</td><td>True  </td><td>11b6545873f0</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">1.09828</td><td>172.28.0.12</td><td style=\"text-align: right;\">47595</td><td>True               </td><td style=\"text-align: right;\">             34.1798</td><td style=\"text-align: right;\">           34.1798</td><td style=\"text-align: right;\">       34.1798</td><td style=\"text-align: right;\"> 1685581519</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">41489_00001</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>\n",
              "<style>\n",
              ".trialProgress {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".trialProgress h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".trialProgress td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-01 01:05:20,055\tINFO tune.py:945 -- Total run time: 53.12 seconds (53.05 seconds for the tuning loop).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial final validation loss: 1.0982751506169637\n",
            "Best trial final validation accuracy: 0.6550833333333334\n",
            "a:      {'opt': 'SGD', 'l1': 32, 'l2': 16, 'lr': 0.01, 'batch_size': 32, 'dropout': 0.2}\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-150-7f8c117b4a91>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-143-eb8c556487b6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mbest_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparam_search2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ASHA\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_num_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconcurrent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a:     \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mbest_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparam_search2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ASHA\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_num_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconcurrent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
